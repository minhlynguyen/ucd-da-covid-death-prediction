import pandas as pd
import os
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score

# TASK 3
# Load the dataset
df = pd.read_csv("C:/Users/MSI-Pc/Desktop/DA-H2/covid19-cdc-cleaned-22201371-22202474-utf8.csv", low_memory=False)

# descriptive features (continuous dropped)
categorical_features = ["case_month", "res_state", "age_group", "sex", "race", "ethnicity", "process", "current_status", "symptom_status", "hosp_yn", "icu_yn"]

# identify target feature
target_feature = "death_yn"

# Preprocess the data
X_categorical = df[categorical_features]
y = df[target_feature]

# Replace missing values in categorical features with a constant string
X_categorical = X_categorical.fillna("missing")

# One-hot encode categorical variables
X_categorical = pd.get_dummies(X_categorical)

# Assign the processed categorical features to X
X = X_categorical

# Split the data into training and test sets (70% training, 30% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 3.1 Train a logistic regression model
lr = LogisticRegression(max_iter=1000)
lr.fit(X_train, y_train)

# 3.2 Print coefficients
coefficients = pd.DataFrame(lr.coef_[0], X.columns, columns=["Coefficient"])
print(coefficients)

# 3.3 Predict target feature values and class for the first 10 training examples
y_train_pred = lr.predict(X_train)
y_train_pred_prob = lr.predict_proba(X_train)[:, 1]

print("Predicted target feature values for the first 10 training examples:")
print(y_train_pred_prob[:10])
print("Predicted class for the first 10 training examples:")
print(y_train_pred[:10])

# 3.3 Compute evaluation metrics on the full training set
accuracy = accuracy_score(y_train, y_train_pred)
conf_matrix = confusion_matrix(y_train, y_train_pred)
precision = precision_score(y_train, y_train_pred, pos_label="Yes")
recall = recall_score(y_train, y_train_pred, pos_label="Yes")
f1 = f1_score(y_train, y_train_pred, pos_label="Yes")

print("Accuracy:", accuracy)
print("Confusion Matrix:\n", conf_matrix)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)

# 3.4 Evaluate the model on the hold-out test set
y_test_pred = lr.predict(X_test)
test_accuracy = accuracy_score(y_test, y_test_pred)
test_precision = precision_score(y_test, y_test_pred, pos_label="Yes")
test_recall = recall_score(y_test, y_test_pred, pos_label="Yes")
test_f1 = f1_score(y_test, y_test_pred, pos_label="Yes")

print("Test Accuracy:", test_accuracy)
print("Test Precision:", test_precision)
print("Test Recall:", test_recall)
print("Test F1 Score:", test_f1)

# 3.4 Cross-validated model
from sklearn.model_selection import cross_val_score

lr_cv = LogisticRegression(max_iter=1000)
accuracy_scores = cross_val_score(lr_cv, X, y, cv=5, scoring='accuracy')
precision_scores = cross_val_score(lr_cv, X, y, cv=5, scoring='precision_macro')
recall_scores = cross_val_score(lr_cv, X, y, cv=5, scoring='recall_macro')
f1_scores = cross_val_score(lr_cv, X, y, cv=5, scoring='f1_macro')

print("Cross-validated Accuracy:", np.mean(accuracy_scores))
print("Cross-validated Precision:", np.mean(precision_scores))
print("Cross-validated Recall:", np.mean(recall_scores))
print("Cross-validated F1 Score:", np.mean(f1_scores))


# TASK 4
# Import random forest classifier
from sklearn.ensemble import RandomForestClassifier

# 4.1 train the random forest model on the training set
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)

# 4.3 Predict the target feature values and classes for the first 10 training examples, and compute evaluation metrics on the full training set
y_train_rf_pred = rf.predict(X_train)
y_train_rf_pred_prob = rf.predict_proba(X_train)[:, 1]

print("Predicted target feature values for the first 10 training examples:")
print(y_train_rf_pred_prob[:10])
print("Predicted class for the first 10 training examples:")
print(y_train_rf_pred[:10])

accuracy_rf = accuracy_score(y_train, y_train_rf_pred)
conf_matrix_rf = confusion_matrix(y_train, y_train_rf_pred)
precision_rf = precision_score(y_train, y_train_rf_pred, pos_label="Yes")
recall_rf = recall_score(y_train, y_train_rf_pred, pos_label="Yes")
f1_rf = f1_score(y_train, y_train_rf_pred, pos_label="Yes")

print("Accuracy:", accuracy_rf)
print("Confusion Matrix:\n", conf_matrix_rf)
print("Precision:", precision_rf)
print("Recall:", recall_rf)
print("F1 Score:", f1_rf)

# 4.4 Evaluate the model on the hold-out test set, compare results with the training dataset, and perform cross-validation

y_test_rf_pred = rf.predict(X_test)
test_accuracy_rf = accuracy_score(y_test, y_test_rf_pred)
test_precision_rf = precision_score(y_test, y_test_rf_pred, pos_label="Yes")
test_recall_rf = recall_score(y_test, y_test_rf_pred, pos_label="Yes")
test_f1_rf = f1_score(y_test, y_test_rf_pred, pos_label="Yes")

print("Test Accuracy:", test_accuracy_rf)
print("Test Precision:", test_precision_rf)
print("Test Recall:", test_recall_rf)
print("Test F1 Score:", test_f1_rf)

rf_cv = RandomForestClassifier(random_state=42)
accuracy_scores_rf = cross_val_score(rf_cv, X, y, cv=5, scoring='accuracy')
precision_scores_rf = cross_val_score(rf_cv, X, y, cv=5, scoring='precision_macro')
recall_scores_rf = cross_val_score(rf_cv, X, y, cv=5, scoring='recall_macro')
f1_scores_rf = cross_val_score(rf_cv, X, y, cv=5, scoring='f1_macro')

print("Cross-validated Accuracy:", np.mean(accuracy_scores_rf))
print("Cross-validated Precision:", np.mean(precision_scores_rf))
print("Cross-validated Recall:", np.mean(recall_scores_rf))
print("Cross-validated F1 Score:", np.mean(f1_scores_rf))

